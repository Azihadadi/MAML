{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "meta_learning_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM9nh6vK2h4I",
        "outputId": "64e95eaf-a634-4d21-8551-2a32b898ca47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQbHCuumPn8V",
        "outputId": "5ee18b4c-9713-4ad5-e2f5-fc9f1011aec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd /content/drive/My Drive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAwmxIrV8m9S",
        "outputId": "f1564fb1-82ee-4c15-e85e-813b4260c194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT95c1QM8vTt",
        "outputId": "2517bca5-f836-4ed2-e91b-fadf54d92cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU (s):\n",
            "3.262742194000026\n",
            "GPU (s):\n",
            "0.10515487899999698\n",
            "GPU speedup over CPU: 31x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uu3XGJE2inz",
        "outputId": "bbcce87f-27ef-4442-af04-5051b3dad304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torchmeta\n",
        "!pip install torch\n",
        "!pip install torchvision"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchmeta in /usr/local/lib/python3.6/dist-packages (1.6.0)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (7.0.0)\n",
            "Requirement already satisfied: torch<1.8.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torchmeta) (2.10.0)\n",
            "Requirement already satisfied: torchvision<0.9.0,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (0.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchmeta) (2.23.0)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.6/dist-packages (from torchmeta) (4.0.2)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from torchmeta) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.4.0->torchmeta) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.4.0->torchmeta) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.4.0->torchmeta) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torchmeta) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchmeta) (3.0.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkmBlBqiqvgQ"
      },
      "source": [
        "#utils\n",
        "import torch\n",
        "\n",
        "from collections import OrderedDict\n",
        "from torchmeta.modules import MetaModule\n",
        "\n",
        "\n",
        "def compute_accuracy(logits, targets):\n",
        "    \"\"\"Compute the accuracy\"\"\"\n",
        "    with torch.no_grad():\n",
        "        _, predictions = torch.max(logits, dim=1)\n",
        "        accuracy = torch.mean(predictions.eq(targets).float())\n",
        "    return accuracy.item()\n",
        "\n",
        "def tensors_to_device(tensors, device=torch.device('cpu')):\n",
        "    \"\"\"Place a collection of tensors in a specific device\"\"\"\n",
        "    if isinstance(tensors, torch.Tensor):\n",
        "        return tensors.to(device=device)\n",
        "    elif isinstance(tensors, (list, tuple)):\n",
        "        return type(tensors)(tensors_to_device(tensor, device=device)\n",
        "            for tensor in tensors)\n",
        "    elif isinstance(tensors, (dict, OrderedDict)):\n",
        "        return type(tensors)([(name, tensors_to_device(tensor, device=device))\n",
        "            for (name, tensor) in tensors.items()])\n",
        "    else:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "class ToTensor1D(object):\n",
        "    \"\"\"Convert a `numpy.ndarray` to tensor. Unlike `ToTensor` from torchvision,\n",
        "    this converts numpy arrays regardless of the number of dimensions.\n",
        "\n",
        "    Converts automatically the array to `float32`.\n",
        "    \"\"\"\n",
        "    def __call__(self, array):\n",
        "        return torch.from_numpy(array.astype('float32'))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '()'\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOuujq-FqRJI"
      },
      "source": [
        "#model\n",
        "import torch.nn as nn\n",
        "\n",
        "from collections import OrderedDict\n",
        "from torchmeta.modules import (MetaModule, MetaConv2d, MetaBatchNorm2d,\n",
        "                               MetaSequential, MetaLinear)\n",
        "\n",
        "\n",
        "def conv_block(in_channels, out_channels, **kwargs):\n",
        "    return MetaSequential(OrderedDict([\n",
        "        ('conv', MetaConv2d(in_channels, out_channels, **kwargs)),\n",
        "        ('norm', nn.BatchNorm2d(out_channels, momentum=1.,\n",
        "            track_running_stats=False)),\n",
        "        ('relu', nn.ReLU()),\n",
        "        ('pool', nn.MaxPool2d(2))\n",
        "    ]))\n",
        "\n",
        "class MetaConvModel(MetaModule):\n",
        "    \"\"\"4-layer Convolutional Neural Network architecture from [1].\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : int\n",
        "        Number of channels for the input images.\n",
        "\n",
        "    out_features : int\n",
        "        Number of classes (output of the model).\n",
        "\n",
        "    hidden_size : int (default: 64)\n",
        "        Number of channels in the intermediate representations.\n",
        "\n",
        "    feature_size : int (default: 64)\n",
        "        Number of features returned by the convolutional head.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Finn C., Abbeel P., and Levine, S. (2017). Model-Agnostic Meta-Learning\n",
        "           for Fast Adaptation of Deep Networks. International Conference on\n",
        "           Machine Learning (ICML) (https://arxiv.org/abs/1703.03400)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_features, hidden_size=64, feature_size=64):\n",
        "        super(MetaConvModel, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_features = out_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.feature_size = feature_size\n",
        "\n",
        "        self.features = MetaSequential(OrderedDict([\n",
        "            ('layer1', conv_block(in_channels, hidden_size, kernel_size=3,\n",
        "                                  stride=1, padding=1, bias=True)),\n",
        "            ('layer2', conv_block(hidden_size, hidden_size, kernel_size=3,\n",
        "                                  stride=1, padding=1, bias=True)),\n",
        "            ('layer3', conv_block(hidden_size, hidden_size, kernel_size=3,\n",
        "                                  stride=1, padding=1, bias=True)),\n",
        "            ('layer4', conv_block(hidden_size, hidden_size, kernel_size=3,\n",
        "                                  stride=1, padding=1, bias=True))\n",
        "        ]))\n",
        "        self.classifier = MetaLinear(feature_size, out_features, bias=True)\n",
        "\n",
        "    def forward(self, inputs, params=None):\n",
        "        features = self.features(inputs, params=self.get_subdict(params, 'features'))\n",
        "        features = features.view((features.size(0), -1))\n",
        "        logits = self.classifier(features, params=self.get_subdict(params, 'classifier'))\n",
        "        return logits\n",
        "\n",
        "class MetaMLPModel(MetaModule):\n",
        "    \"\"\"Multi-layer Perceptron architecture from [1].\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_features : int\n",
        "        Number of input features.\n",
        "\n",
        "    out_features : int\n",
        "        Number of classes (output of the model).\n",
        "\n",
        "    hidden_sizes : list of int\n",
        "        Size of the intermediate representations. The length of this list\n",
        "        corresponds to the number of hidden layers.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Finn C., Abbeel P., and Levine, S. (2017). Model-Agnostic Meta-Learning\n",
        "           for Fast Adaptation of Deep Networks. International Conference on\n",
        "           Machine Learning (ICML) (https://arxiv.org/abs/1703.03400)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, hidden_sizes):\n",
        "        super(MetaMLPModel, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.hidden_sizes = hidden_sizes\n",
        "\n",
        "        layer_sizes = [in_features] + hidden_sizes\n",
        "        self.features = MetaSequential(OrderedDict([('layer{0}'.format(i + 1),\n",
        "            MetaSequential(OrderedDict([\n",
        "                ('linear', MetaLinear(hidden_size, layer_sizes[i + 1], bias=True)),\n",
        "                ('relu', nn.ReLU())\n",
        "            ]))) for (i, hidden_size) in enumerate(layer_sizes[:-1])]))\n",
        "        self.classifier = MetaLinear(hidden_sizes[-1], out_features, bias=True)\n",
        "\n",
        "    def forward(self, inputs, params=None):\n",
        "        features = self.features(inputs, params=self.get_subdict(params, 'features'))\n",
        "        logits = self.classifier(features, params=self.get_subdict(params, 'classifier'))\n",
        "        return logits\n",
        "\n",
        "def ModelConvOmniglot(out_features, hidden_size=64):\n",
        "    return MetaConvModel(1, out_features, hidden_size=hidden_size,\n",
        "                         feature_size=hidden_size)\n",
        "\n",
        "def ModelConvMiniImagenet(out_features, hidden_size=64):\n",
        "    return MetaConvModel(3, out_features, hidden_size=hidden_size,\n",
        "                         feature_size=5 * 5 * hidden_size)\n",
        "\n",
        "def ModelMLPSinusoid(hidden_sizes=[40, 40]):\n",
        "    return MetaMLPModel(1, 1, hidden_sizes)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = ModelMLPSinusoid()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK5qnWdZ2itk"
      },
      "source": [
        "# maml\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import OrderedDict\n",
        "from torchmeta.utils import gradient_update_parameters\n",
        "\n",
        "__all__ = ['ModelAgnosticMetaLearning', 'MAML', 'FOMAML']\n",
        "\n",
        "\n",
        "class ModelAgnosticMetaLearning(object):\n",
        "    \"\"\"Meta-learner class for Model-Agnostic Meta-Learning [1].\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : `torchmeta.modules.MetaModule` instance\n",
        "        The model.\n",
        "\n",
        "    optimizer : `torch.optim.Optimizer` instance, optional\n",
        "        The optimizer for the outer-loop optimization procedure. This argument\n",
        "        is optional for evaluation.\n",
        "\n",
        "    step_size : float (default: 0.1)\n",
        "        The step size of the gradient descent update for fast adaptation\n",
        "        (inner-loop update).\n",
        "\n",
        "    first_order : bool (default: False)\n",
        "        If `True`, then the first-order approximation of MAML is used.\n",
        "\n",
        "    learn_step_size : bool (default: False)\n",
        "        If `True`, then the step size is a learnable (meta-trained) additional\n",
        "        argument [2].\n",
        "\n",
        "    per_param_step_size : bool (default: False)\n",
        "        If `True`, then the step size parameter is different for each parameter\n",
        "        of the model. Has no impact unless `learn_step_size=True`.\n",
        "\n",
        "    num_adaptation_steps : int (default: 1)\n",
        "        The number of gradient descent updates on the loss function (over the\n",
        "        training dataset) to be used for the fast adaptation on a new task.\n",
        "\n",
        "    scheduler : object in `torch.optim.lr_scheduler`, optional\n",
        "        Scheduler for the outer-loop optimization [3].\n",
        "\n",
        "    loss_function : callable (default: `torch.nn.functional.cross_entropy`)\n",
        "        The loss function for both the inner and outer-loop optimization.\n",
        "        Usually `torch.nn.functional.cross_entropy` for a classification\n",
        "        problem, of `torch.nn.functional.mse_loss` for a regression problem.\n",
        "\n",
        "    device : `torch.device` instance, optional\n",
        "        The device on which the model is defined.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Finn C., Abbeel P., and Levine, S. (2017). Model-Agnostic Meta-Learning\n",
        "           for Fast Adaptation of Deep Networks. International Conference on\n",
        "           Machine Learning (ICML) (https://arxiv.org/abs/1703.03400)\n",
        "\n",
        "    .. [2] Li Z., Zhou F., Chen F., Li H. (2017). Meta-SGD: Learning to Learn\n",
        "           Quickly for Few-Shot Learning. (https://arxiv.org/abs/1707.09835)\n",
        "\n",
        "    .. [3] Antoniou A., Edwards H., Storkey A. (2018). How to train your MAML.\n",
        "           International Conference on Learning Representations (ICLR).\n",
        "           (https://arxiv.org/abs/1810.09502)\n",
        "    \"\"\"\n",
        "    def __init__(self, model, optimizer=None, step_size=0.1, first_order=False,\n",
        "                 learn_step_size=False, per_param_step_size=False,\n",
        "                 num_adaptation_steps=1, scheduler=None,\n",
        "                 loss_function=F.cross_entropy, device=None):\n",
        "        self.model = model.to(device=device)\n",
        "        self.optimizer = optimizer\n",
        "        self.step_size = step_size\n",
        "        self.first_order = first_order\n",
        "        self.num_adaptation_steps = num_adaptation_steps\n",
        "        self.scheduler = scheduler\n",
        "        self.loss_function = loss_function\n",
        "        self.device = device\n",
        "\n",
        "        if per_param_step_size:\n",
        "            self.step_size = OrderedDict((name, torch.tensor(step_size,\n",
        "                dtype=param.dtype, device=self.device,\n",
        "                requires_grad=learn_step_size)) for (name, param)\n",
        "                in model.meta_named_parameters())\n",
        "        else:\n",
        "            self.step_size = torch.tensor(step_size, dtype=torch.float32,\n",
        "                device=self.device, requires_grad=learn_step_size)\n",
        "\n",
        "        if (self.optimizer is not None) and learn_step_size:\n",
        "            self.optimizer.add_param_group({'params': self.step_size.values()\n",
        "                if per_param_step_size else [self.step_size]})\n",
        "            if scheduler is not None:\n",
        "                for group in self.optimizer.param_groups:\n",
        "                    group.setdefault('initial_lr', group['lr'])\n",
        "                self.scheduler.base_lrs([group['initial_lr']\n",
        "                    for group in self.optimizer.param_groups])\n",
        "\n",
        "    def get_outer_loss(self, batch):\n",
        "        if 'test' not in batch:\n",
        "            raise RuntimeError('The batch does not contain any test dataset.')\n",
        "\n",
        "        _, test_targets = batch['test']\n",
        "        num_tasks = test_targets.size(0)\n",
        "        is_classification_task = (not test_targets.dtype.is_floating_point)\n",
        "        results = {\n",
        "            'num_tasks': num_tasks,\n",
        "            'inner_losses': np.zeros((self.num_adaptation_steps,\n",
        "                num_tasks), dtype=np.float32),\n",
        "            'outer_losses': np.zeros((num_tasks,), dtype=np.float32),\n",
        "            'mean_outer_loss': 0.\n",
        "        }\n",
        "        if is_classification_task:\n",
        "            results.update({\n",
        "                'accuracies_before': np.zeros((num_tasks,), dtype=np.float32),\n",
        "                'accuracies_after': np.zeros((num_tasks,), dtype=np.float32)\n",
        "            })\n",
        "\n",
        "        mean_outer_loss = torch.tensor(0., device=self.device)\n",
        "        for task_id, (train_inputs, train_targets, test_inputs, test_targets) \\\n",
        "                in enumerate(zip(*batch['train'], *batch['test'])):\n",
        "            params, adaptation_results = self.adapt(train_inputs, train_targets,\n",
        "                is_classification_task=is_classification_task,\n",
        "                num_adaptation_steps=self.num_adaptation_steps,\n",
        "                step_size=self.step_size, first_order=self.first_order)\n",
        "\n",
        "            results['inner_losses'][:, task_id] = adaptation_results['inner_losses']\n",
        "            if is_classification_task:\n",
        "                results['accuracies_before'][task_id] = adaptation_results['accuracy_before']\n",
        "\n",
        "            with torch.set_grad_enabled(self.model.training):\n",
        "                test_logits = self.model(test_inputs, params=params)\n",
        "                outer_loss = self.loss_function(test_logits, test_targets)\n",
        "                results['outer_losses'][task_id] = outer_loss.item()\n",
        "                mean_outer_loss += outer_loss\n",
        "\n",
        "            if is_classification_task:\n",
        "                results['accuracies_after'][task_id] = compute_accuracy(\n",
        "                    test_logits, test_targets)\n",
        "\n",
        "        mean_outer_loss.div_(num_tasks)\n",
        "        results['mean_outer_loss'] = mean_outer_loss.item()\n",
        "\n",
        "        return mean_outer_loss, results\n",
        "\n",
        "    def adapt(self, inputs, targets, is_classification_task=None,\n",
        "              num_adaptation_steps=1, step_size=0.1, first_order=False):\n",
        "        if is_classification_task is None:\n",
        "            is_classification_task = (not targets.dtype.is_floating_point)\n",
        "        params = None\n",
        "\n",
        "        results = {'inner_losses': np.zeros(\n",
        "            (num_adaptation_steps,), dtype=np.float32)}\n",
        "\n",
        "        for step in range(num_adaptation_steps):\n",
        "            logits = self.model(inputs, params=params)\n",
        "            inner_loss = self.loss_function(logits, targets)\n",
        "            results['inner_losses'][step] = inner_loss.item()\n",
        "\n",
        "            if (step == 0) and is_classification_task:\n",
        "                results['accuracy_before'] = compute_accuracy(logits, targets)\n",
        "\n",
        "            self.model.zero_grad()\n",
        "            params = gradient_update_parameters(self.model, inner_loss,\n",
        "                step_size=step_size, params=params,\n",
        "                first_order=(not self.model.training) or first_order)\n",
        "\n",
        "        return params, results\n",
        "\n",
        "    def train(self, dataloader, max_batches=500, verbose=True, **kwargs):\n",
        "        # with tqdm(total=max_batches, disable=not verbose, **kwargs) as pbar:\n",
        "        acc_list = []\n",
        "        loss_list=[]\n",
        "        with tqdm(total=max_batches,**kwargs) as pbar:\n",
        "            for results in self.train_iter(dataloader, max_batches=max_batches):\n",
        "                # pbar.update(1)\n",
        "                postfix = {'loss': '{0:.4f}'.format(results['mean_outer_loss'])}\n",
        "                loss_list.append(results['mean_outer_loss'])\n",
        "                if 'accuracies_after' in results:\n",
        "                    postfix['accuracy'] = '{0:.4f}'.format(\n",
        "                        np.mean(results['accuracies_after']))          \n",
        "                    \n",
        "                    acc_list.append(np.mean(results['accuracies_after']))\n",
        "                pbar.set_postfix(**postfix)                  \n",
        "        return (acc_list,loss_list)\n",
        "\n",
        "    def train_iter(self, dataloader, max_batches=500):\n",
        "        if self.optimizer is None:\n",
        "            raise RuntimeError('Trying to call `train_iter`, while the '\n",
        "                'optimizer is `None`. In order to train `{0}`, you must '\n",
        "                'specify a Pytorch optimizer as the argument of `{0}` '\n",
        "                '(eg. `{0}(model, optimizer=torch.optim.SGD(model.'\n",
        "                'parameters(), lr=0.01), ...).'.format(__class__.__name__))\n",
        "        num_batches = 0\n",
        "        self.model.train()\n",
        "        while num_batches < max_batches:\n",
        "            for batch in dataloader:\n",
        "                if num_batches >= max_batches:\n",
        "                    break\n",
        "\n",
        "                if self.scheduler is not None:\n",
        "                    self.scheduler.step(epoch=num_batches)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                batch = tensors_to_device(batch, device=self.device)\n",
        "                outer_loss, results = self.get_outer_loss(batch)\n",
        "                yield results\n",
        "\n",
        "                outer_loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                num_batches += 1\n",
        "\n",
        "    def evaluate(self, dataloader, max_batches=500, verbose=True, **kwargs):\n",
        "        mean_outer_loss, mean_accuracy, count = 0., 0., 0\n",
        "\n",
        "        # with tqdm(total=max_batches, disable=not verbose, **kwargs) as pbar:\n",
        "        with tqdm(total=max_batches, **kwargs) as pbar:\n",
        "            for results in self.evaluate_iter(dataloader, max_batches=max_batches):\n",
        "                pbar.update(1)\n",
        "                count += 1\n",
        "                mean_outer_loss += (results['mean_outer_loss']\n",
        "                    - mean_outer_loss) / count\n",
        "                postfix = {'loss': '{0:.4f}'.format(mean_outer_loss)}                \n",
        "                if 'accuracies_after' in results:\n",
        "                    mean_accuracy += (np.mean(results['accuracies_after'])\n",
        "                        - mean_accuracy) / count\n",
        "                    postfix['accuracy'] = '{0:.4f}'.format(mean_accuracy)                    \n",
        "                pbar.set_postfix(**postfix)\n",
        "        mean_results = {'mean_outer_loss': mean_outer_loss}\n",
        "        if 'accuracies_after' in results:\n",
        "            mean_results['accuracies_after'] = mean_accuracy\n",
        "\n",
        "        return (mean_results)\n",
        "\n",
        "    def evaluate_iter(self, dataloader, max_batches=500):\n",
        "        num_batches = 0\n",
        "        self.model.eval()\n",
        "        while num_batches < max_batches:\n",
        "            for batch in dataloader:\n",
        "                if num_batches >= max_batches:\n",
        "                    break\n",
        "\n",
        "                batch = tensors_to_device(batch, device=self.device)\n",
        "                _, results = self.get_outer_loss(batch)\n",
        "                yield results\n",
        "\n",
        "                num_batches += 1\n",
        "\n",
        "MAML = ModelAgnosticMetaLearning\n",
        "\n",
        "class FOMAML(ModelAgnosticMetaLearning):\n",
        "    def __init__(self, model, optimizer=None, step_size=0.1,\n",
        "                 learn_step_size=False, per_param_step_size=False,\n",
        "                 num_adaptation_steps=1, scheduler=None,\n",
        "                 loss_function=F.cross_entropy, device=None):\n",
        "        super(FOMAML, self).__init__(model, optimizer=optimizer, first_order=True,\n",
        "            step_size=step_size, learn_step_size=learn_step_size,\n",
        "            per_param_step_size=per_param_step_size,\n",
        "            num_adaptation_steps=num_adaptation_steps, scheduler=scheduler,\n",
        "            loss_function=loss_function, device=device)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQf5fVvBqiKQ"
      },
      "source": [
        "# meta_sgd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "__all__ = ['MetaSGD']\n",
        "\n",
        "\n",
        "class MetaSGD(ModelAgnosticMetaLearning):\n",
        "    def __init__(self, model, optimizer=None, init_step_size=0.1,\n",
        "                 num_adaptation_steps=1, scheduler=None,\n",
        "                 loss_function=F.cross_entropy, device=None):\n",
        "        super(MetaSGD, self).__init__(model, optimizer=optimizer,\n",
        "            step_size=init_step_size, learn_step_size=True,\n",
        "            per_param_step_size=True, num_adaptation_steps=num_adaptation_steps,\n",
        "            scheduler=scheduler, loss_function=loss_function, device=device)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vhur7p6qmQg"
      },
      "source": [
        "#datasets\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import namedtuple\n",
        "from torchmeta.datasets import Omniglot, MiniImagenet\n",
        "from torchmeta.toy import Sinusoid\n",
        "from torchmeta.transforms import ClassSplitter, Categorical, Rotation\n",
        "from torchvision.transforms import ToTensor, Resize, Compose\n",
        "\n",
        "Benchmark = namedtuple('Benchmark', 'meta_train_dataset meta_val_dataset '\n",
        "                                    'meta_test_dataset model loss_function')\n",
        "\n",
        "def get_benchmark_by_name(name,\n",
        "                          folder,\n",
        "                          numWays,\n",
        "                          numShots,\n",
        "                          numShotsTest,\n",
        "                          hidden_size=None):\n",
        "    dataset_transform = ClassSplitter(shuffle=True,\n",
        "                                      num_train_per_class=numShots,\n",
        "                                      num_test_per_class=numShotsTest)\n",
        "    if name == 'sinusoid':\n",
        "        transform = ToTensor1D()\n",
        "\n",
        "        meta_train_dataset = Sinusoid(numShots + numShotsTest,\n",
        "                                      num_tasks=1000000,\n",
        "                                      transform=transform,\n",
        "                                      target_transform=transform,\n",
        "                                      dataset_transform=dataset_transform)\n",
        "        meta_val_dataset = Sinusoid(numShots + numShotsTest,\n",
        "                                    num_tasks=1000000,\n",
        "                                    transform=transform,\n",
        "                                    target_transform=transform,\n",
        "                                    dataset_transform=dataset_transform)\n",
        "        meta_test_dataset = Sinusoid(numShots + numShotsTest,\n",
        "                                     num_tasks=1000000,\n",
        "                                     transform=transform,\n",
        "                                     target_transform=transform,\n",
        "                                     dataset_transform=dataset_transform)\n",
        "\n",
        "        model = ModelMLPSinusoid(hidden_sizes=[40, 40])\n",
        "        loss_function = F.mse_loss\n",
        "\n",
        "    elif name == 'omniglot':\n",
        "        class_augmentations = [Rotation([90, 180, 270])]\n",
        "        transform = Compose([Resize(28), ToTensor()])\n",
        "\n",
        "        meta_train_dataset = Omniglot(folder,\n",
        "                                      transform=transform,\n",
        "                                      target_transform=Categorical(numWays),\n",
        "                                      num_classes_per_task=numWays,\n",
        "                                      meta_train=True,\n",
        "                                      class_augmentations=class_augmentations,\n",
        "                                      dataset_transform=dataset_transform,\n",
        "                                      download=True)\n",
        "        meta_val_dataset = Omniglot(folder,\n",
        "                                    transform=transform,\n",
        "                                    target_transform=Categorical(numWays),\n",
        "                                    num_classes_per_task=numWays,\n",
        "                                    meta_val=True,\n",
        "                                    class_augmentations=class_augmentations,\n",
        "                                    dataset_transform=dataset_transform)\n",
        "        meta_test_dataset = Omniglot(folder,\n",
        "                                     transform=transform,\n",
        "                                     target_transform=Categorical(numWays),\n",
        "                                     num_classes_per_task=numWays,\n",
        "                                     meta_test=True,\n",
        "                                     dataset_transform=dataset_transform)\n",
        "\n",
        "        model = ModelConvOmniglot(numWays, hidden_size=hidden_size)\n",
        "        loss_function = F.cross_entropy\n",
        "\n",
        "    elif name == 'miniimagenet':\n",
        "        transform = Compose([Resize(84), ToTensor()])\n",
        "\n",
        "        meta_train_dataset = MiniImagenet(folder,\n",
        "                                          transform=transform,\n",
        "                                          target_transform=Categorical(numWays),\n",
        "                                          num_classes_per_task=numWays,\n",
        "                                          meta_train=True,\n",
        "                                          dataset_transform=dataset_transform,\n",
        "                                          download=True)\n",
        "        meta_val_dataset = MiniImagenet(folder,\n",
        "                                        transform=transform,\n",
        "                                        target_transform=Categorical(numWays),\n",
        "                                        num_classes_per_task=numWays,\n",
        "                                        meta_val=True,\n",
        "                                        dataset_transform=dataset_transform)\n",
        "        meta_test_dataset = MiniImagenet(folder,\n",
        "                                         transform=transform,\n",
        "                                         target_transform=Categorical(numWays),\n",
        "                                         num_classes_per_task=numWays,\n",
        "                                         meta_test=True,\n",
        "                                         dataset_transform=dataset_transform)\n",
        "\n",
        "        model = ModelConvMiniImagenet(numWays, hidden_size=hidden_size)\n",
        "        loss_function = F.cross_entropy\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError('Unknown dataset `{0}`.'.format(name))\n",
        "\n",
        "    return Benchmark(meta_train_dataset=meta_train_dataset,\n",
        "                     meta_val_dataset=meta_val_dataset,\n",
        "                     meta_test_dataset=meta_test_dataset,\n",
        "                     model=model,\n",
        "                     loss_function=loss_function)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqEUR6bMq2hg",
        "outputId": "9a8500a6-35be-4e6e-aa86-1f9b63f6868c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "#train\n",
        "#************* Please create 2 folders on your Drive called: data , out**************\n",
        "import torch\n",
        "import math\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "\n",
        "from torchmeta.utils.data import BatchMetaDataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# General\n",
        "folder = os.path.join(\".\",'data')#Path to the folder the data is downloaded to.\n",
        "dataset = 'omniglot'#Name of the dataset (default: omniglot).\n",
        "outputFolder = os.path.join(\".\",'out')#Path to the output folder to save the model.\n",
        "numWays=5 #Number of classes per task (N in \"N-way\", default: 5).\n",
        "numShots = 5 #Number of training example per class (k in \"k-shot\", default: 5).\n",
        "numShotsTest = 15 #Number of test example per class. If negative, same as the number of training examples `--num-shots` (default: 15).\n",
        "\n",
        "# Model\n",
        "hiddenSize = 64 #Number of channels in each convolution layer of the VGG network (default: 64).\n",
        "\n",
        "# Optimization\n",
        "batchSize =32 #Number of tasks in a batch of tasks (default: 25).').\n",
        "numSteps = 1 #Number of fast adaptation steps, ie. gradient descent updates (default: 1).\n",
        "numEpochs = 1 #Number of epochs of meta-training (default: 50).\n",
        "numBatches = 100 #Number of batch of tasks per epoch (default: 100).\n",
        "stepSize = 0.4 #Size of the fast adaptation step, ie. learning rate in the gradient descent update (default: 0.1).\n",
        "firstOrder = False #Use the first order approximation, do not use higher-order derivatives during meta-optimization.\n",
        "metaLr =0.001 #Learning rate for the meta-optimizer (optimization of the outer loss). The default optimizer is Adam (default: 1e-3).\n",
        "\n",
        "# Misc\n",
        "numWorkers = 8 #Number of workers to use for data-loading (default: 1).\n",
        "verbose = False\n",
        "useCuda = True\n",
        "\n",
        "# \n",
        "logging.basicConfig(level=logging.DEBUG if verbose else logging.INFO)\n",
        "device = torch.device('cuda' if useCuda\n",
        "                        and torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "if (outputFolder is not None):\n",
        "    if not os.path.exists(outputFolder):\n",
        "        os.makedirs(outputFolder)\n",
        "        logging.debug('Creating folder `{0}`'.format(outputFolder))\n",
        "\n",
        "    folderOutCreated = os.path.join(outputFolder,\n",
        "                          time.strftime('%Y-%m-%d_%H%M%S'))\n",
        "    os.makedirs(folderOutCreated)\n",
        "    logging.debug('Creating folder `{0}`'.format(folderOutCreated))\n",
        "\n",
        "    folder = os.path.abspath(folder)\n",
        "    modelPath = os.path.abspath(os.path.join(folderOutCreated, 'model.th'))\n",
        "    vars = {\"folder\" : folder, \n",
        "            \"dataset\" : dataset,\n",
        "            \"outputFolder\" : outputFolder,\n",
        "            \"numWays\" : numWays,\n",
        "            \"numShots\" : numShots,\n",
        "            \"numShotsTest\" : numShotsTest,\n",
        "            \"hiddenSize\" : hiddenSize,\n",
        "            \"batchSize\" : batchSize, \n",
        "            \"numSteps\" : numSteps ,\n",
        "            \"numEpochs\" : numEpochs ,\n",
        "            \"numBatches\" : numBatches ,\n",
        "            \"stepSize\" : stepSize ,\n",
        "            \"firstOrder\" : firstOrder,\n",
        "            \"metaLr\" : metaLr, \n",
        "            \"numWorkers\" : numWorkers, \n",
        "            \"verbose\" : verbose,\n",
        "            \"useCuda\" : useCuda,\n",
        "            \"modelPath\" : modelPath}\n",
        "    # Save the configuration in a config.json file\n",
        "    with open(os.path.join(folderOutCreated, 'config.json'), 'w') as f:\n",
        "        json.dump(vars, f, indent=2)\n",
        "    logging.info('Saving configuration file in `{0}`'.format(\n",
        "                  os.path.abspath(os.path.join(folderOutCreated, 'config.json'))))\n",
        "\n",
        "benchmark = get_benchmark_by_name(dataset,\n",
        "                                      folder,\n",
        "                                      numWays,\n",
        "                                      numShots,\n",
        "                                      numShotsTest,\n",
        "                                      hidden_size=hiddenSize)\n",
        "\n",
        "meta_train_dataloader = BatchMetaDataLoader(benchmark.meta_train_dataset,\n",
        "                                                batch_size=batchSize,\n",
        "                                                shuffle=True,\n",
        "                                                num_workers=numWorkers,\n",
        "                                                pin_memory=True)\n",
        "meta_val_dataloader = BatchMetaDataLoader(benchmark.meta_val_dataset,\n",
        "                                              batch_size=batchSize,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=numWorkers,\n",
        "                                              pin_memory=True)\n",
        "\n",
        "meta_optimizer = torch.optim.Adam(benchmark.model.parameters(), lr=metaLr)\n",
        "metalearner = ModelAgnosticMetaLearning(benchmark.model,\n",
        "                                            meta_optimizer,\n",
        "                                            first_order=firstOrder,\n",
        "                                            num_adaptation_steps=numSteps,\n",
        "                                            step_size=stepSize,\n",
        "                                            loss_function=benchmark.loss_function,\n",
        "                                            device=device)\n",
        "\n",
        "best_value = None\n",
        "accuracy_epoch = []\n",
        "loss_epoch = []\n",
        "\n",
        "# Training loop\n",
        "epoch_desc = 'Epoch {{0: <{0}d}}'.format(1 + int(math.log10(numEpochs)))\n",
        "for epoch in range(numEpochs):\n",
        "    (accuracy_list, loss_list) = metalearner.train(meta_train_dataloader,\n",
        "                          max_batches=numBatches,\n",
        "                          verbose=verbose,\n",
        "                          desc='Training',\n",
        "                          leave=False)\n",
        "    results = metalearner.evaluate(meta_val_dataloader,\n",
        "                                       max_batches=numBatches,\n",
        "                                       verbose=verbose,\n",
        "                                       desc=epoch_desc.format(epoch + 1))\n",
        "\n",
        "    # Plot\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()    \n",
        "    plt.plot(np.arange(0, numBatches), loss_list, label=\"Loss\")\n",
        "    plt.plot(np.arange(0, numBatches), accuracy_list, label=\"Accuracy\")\n",
        "    plt.title(\"ROC curve\")\n",
        "    plt.xlabel(\"batch #\")\n",
        "    plt.ylabel(\"Accuracy/Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    # Save best model\n",
        "    if 'accuracies_after' in results:\n",
        "        if (best_value is None) or (best_value < results['accuracies_after']):\n",
        "            best_value = results['accuracies_after']\n",
        "            save_model = True\n",
        "    elif (best_value is None) or (best_value > results['mean_outer_loss']):\n",
        "        best_value = results['mean_outer_loss']\n",
        "        save_model = True\n",
        "    else:\n",
        "        save_model = False\n",
        "\n",
        "\n",
        "    if save_model and (outputFolder is not None):\n",
        "        with open(modelPath, 'wb') as f:\n",
        "            torch.save(benchmark.model.state_dict(), f)           \n",
        "\n",
        "if hasattr(benchmark.meta_train_dataset, 'close'):\n",
        "    benchmark.meta_train_dataset.close()\n",
        "    benchmark.meta_val_dataset.close()\n",
        " "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Saving configuration file in `/content/drive/My Drive/out/2020-11-17_080006/config.json`\n",
            "Epoch 1: 100%|██████████| 100/100 [02:16<00:00,  1.37s/it, accuracy=0.9232, loss=0.3034]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHCv_eW1q4Ky",
        "outputId": "77a3212d-e0fb-460b-ef3f-6f220d82ed5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#test\n",
        "    \n",
        "config = os.path.abspath(os.path.join(folderOutCreated, 'config.json')) #Path to the configuration file .\n",
        "folder = None #Path to the folder the data is downloaded to.(default: path defined in configuration file).\n",
        "\n",
        "# Optimization\n",
        "numSteps = -1 #Number of fast adaptation steps, ie. gradient descent updates (default: number of steps in configuration file).\n",
        "numBatches = -1 #Number of batch of tasks per epoch (default: number of batches in configuration file).\n",
        "\n",
        "# Misc\n",
        "numWorkers = 1 #Number of workers to use for data-loading (default: 1).\n",
        "verbose = False\n",
        "useCuda = True   \n",
        "#\n",
        "with open(config, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "if folder is not None:\n",
        "    config['folder'] = folder\n",
        "if numSteps > 0:\n",
        "    config['numSteps'] = numSteps\n",
        "if numBatches > 0:\n",
        "    config['numBatches'] = numBatches\n",
        "\n",
        "device = torch.device('cuda' if useCuda\n",
        "                      and torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "benchmark = get_benchmark_by_name(config['dataset'],\n",
        "                                      config['folder'],\n",
        "                                      config['numWays'],\n",
        "                                      config['numShots'],\n",
        "                                      config['numShotsTest'],\n",
        "                                      hidden_size=config['hiddenSize'])\n",
        "\n",
        "with open(config['modelPath'], 'rb') as f:\n",
        "    benchmark.model.load_state_dict(torch.load(f, map_location=device))\n",
        "\n",
        "meta_test_dataloader = BatchMetaDataLoader(benchmark.meta_test_dataset,\n",
        "                                               batch_size=config['batchSize'],\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=numWorkers,\n",
        "                                               pin_memory=True)\n",
        "metalearner = ModelAgnosticMetaLearning(benchmark.model,\n",
        "                                            first_order=config['firstOrder'],\n",
        "                                            num_adaptation_steps=config['numSteps'],\n",
        "                                            step_size=config['stepSize'],\n",
        "                                            loss_function=benchmark.loss_function,\n",
        "                                            device= device)\n",
        "\n",
        "results = metalearner.evaluate(meta_test_dataloader,\n",
        "                                   max_batches=config['numBatches'],\n",
        "                                   verbose=verbose,\n",
        "                                   desc='Test')\n",
        "# Save results\n",
        "dirname = os.path.dirname(config['modelPath'])\n",
        "with open(os.path.join(dirname, 'results.json'), 'w') as f:\n",
        "    json.dump(results, f)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test: 100%|██████████| 100/100 [02:20<00:00,  1.40s/it, accuracy=0.9030, loss=0.3418]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}